{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,re,glob,ipykernel,tweepy,stockmarket,nltk,collections,itertools,pandas as pd,numpy as np,\\\n",
    "        seaborn as sns, yfinance as yf, matplotlib.pyplot as plt, statsmodels.formula.api as smf,\\\n",
    "        statsmodels.api as sm, autoreload, importlib\n",
    "from pathlib import Path\n",
    "from string import punctuation \n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Working Directory: \n",
    "    \n",
    "* /Sentiment_Analysis \n",
    "    \n",
    "* __ file __ isn't available in jupyter notebooks\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root directory: c:\\Code\\Public_Github\\Sentiment_Analysis\n"
     ]
    }
   ],
   "source": [
    "file = os.getcwd().split(os.sep)\n",
    "while(file[-1] != 'Sentiment_Analysis'): # Check the working directory\n",
    "    os.chdir('..')\n",
    "    file = os.getcwd().split(os.sep)\n",
    "    sys.path.append(os.path.abspath(os.getcwd()))\n",
    "print(f\"root directory: {os.getcwd()}\", sep = '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import user_download_helper, user_download, merge_files, merge_all, \\\n",
    "                strip_all_words, sentence_word_probability, download_todays_test, \\\n",
    "                format_model,linear_model, naive_bayes, create_target, normalize_columns, normalize_columns_target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in keys from a csv file\n",
    "autentication_path = os.path.abspath('../Sentiment_Analysis/Stock_Market/authentication/authentication_tokens.csv')\n",
    "readin_authentication = pd.read_csv(autentication_path, header=0, sep=',')\n",
    "\n",
    "consumer_key = readin_authentication['consumer_key'][0]\n",
    "consumer_secret = readin_authentication['consumer_secret'][0]\n",
    "access_token = readin_authentication['access_token'][0]\n",
    "access_token_secret = readin_authentication['access_token_secret'][0]\n",
    "bearer_token = readin_authentication['beaker_token'][0]\n",
    "\n",
    "# connect to twitter application \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "redirect_url = auth.get_authorization_url()\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Twitter Usernames\n",
    "\n",
    "    Note:\n",
    "    * Unvarified user's are not a problem, no one user can have the same ID\n",
    "    \n",
    "<div style=\"padding-left: 50px;\">\n",
    "\n",
    "| Removed User's | reason | \n",
    "| ------------ | ------------- |\n",
    "|DayTradeWarrior|account removed |\n",
    "|AswathDamodaran |2013-06-19 |\n",
    "|cstewartcfa_twitter |2013-06-19|\n",
    "|BobPisani_twitter |2015-11-04| \n",
    "|elonmusk|private|\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_term</th>\n",
       "      <th>long_term</th>\n",
       "      <th>controversial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanZanger</td>\n",
       "      <td>jimcramer</td>\n",
       "      <td>JeffBezos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prrobbins</td>\n",
       "      <td>KennethLFisher</td>\n",
       "      <td>BillGates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markminervini</td>\n",
       "      <td>lei_zhang_lz</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bsc_daily</td>\n",
       "      <td>realwillmeade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MITickWatcher</td>\n",
       "      <td>RayDalio</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OptionsProVol</td>\n",
       "      <td>GRDecter</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>script_crypto</td>\n",
       "      <td>andrewrsorkin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MarketMagnifier</td>\n",
       "      <td>EconguyRosie</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TwentyonTwenty_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WatcherGuru</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DipFinding</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MacroCharts</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>techbudsolution</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eWhispers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HindenburgRes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JehoshaphatRsch</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResearchGrizzly</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biancoresearch</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>muddywatersre</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         short_term       long_term controversial\n",
       "0         DanZanger       jimcramer     JeffBezos\n",
       "1         prrobbins  KennethLFisher     BillGates\n",
       "2     markminervini    lei_zhang_lz              \n",
       "3         bsc_daily   realwillmeade              \n",
       "4     MITickWatcher        RayDalio              \n",
       "5     OptionsProVol        GRDecter              \n",
       "6     script_crypto   andrewrsorkin              \n",
       "7   MarketMagnifier    EconguyRosie              \n",
       "8   TwentyonTwenty_                              \n",
       "9       WatcherGuru                              \n",
       "10       DipFinding                              \n",
       "11      MacroCharts                              \n",
       "12  techbudsolution                              \n",
       "13        eWhispers                              \n",
       "14    HindenburgRes                              \n",
       "15  JehoshaphatRsch                              \n",
       "16  ResearchGrizzly                              \n",
       "17   biancoresearch                              \n",
       "18    muddywatersre                              "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.normpath(os.getcwd() + '/Stock_Market/user_list/user_list.xlsx'), 'rb') as f:\n",
    "    user_df = pd.read_excel(f, sheet_name='user_names')\n",
    "    user_df = user_df.where(pd.notnull(user_df), '')\n",
    "    f.close()\n",
    "groups = list(user_df.columns)\n",
    "user_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING ~ 10 minutes\n",
    "    If previously loaded SKIP to CHECKPOINT \n",
    "    * Download User tweets into csv spreadsheets \n",
    "\n",
    "- ( Tweepy limit of 3200 tweets per user )\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "short_term:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m users \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(user_df[group][user_df[group]\u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m user_download(api, users, group)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Code\\Public_Github\\Sentiment_Analysis\\Stock_Market\\src\\preparation\\tweepy_functions.py:84\u001b[0m, in \u001b[0;36muser_download\u001b[1;34m(api, user_list, group)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[39mfor\u001b[39;00m userID \u001b[39min\u001b[39;00m user_list:\n\u001b[1;32m---> 84\u001b[0m         user_download_helper(api, userID, group)\n\u001b[0;32m     85\u001b[0m         \u001b[39mprint\u001b[39m(userID, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Code\\Public_Github\\Sentiment_Analysis\\Stock_Market\\src\\preparation\\tweepy_functions.py:23\u001b[0m, in \u001b[0;36muser_download_helper\u001b[1;34m(api, userID, group)\u001b[0m\n\u001b[0;32m     21\u001b[0m oldest_id \u001b[39m=\u001b[39m tweets[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mid\n\u001b[0;32m     22\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     tweets \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49muser_timeline(screen_name\u001b[39m=\u001b[39;49muserID, \n\u001b[0;32m     24\u001b[0m                         \u001b[39m# 200 is the maximum allowed count\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m                         count\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m                         include_rts \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     27\u001b[0m                         max_id \u001b[39m=\u001b[39;49m oldest_id \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     28\u001b[0m                         trim_user \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     29\u001b[0m                         tweet_mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mextended\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     30\u001b[0m                         )\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tweets) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     32\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_list\n\u001b[0;32m     45\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_type\n\u001b[1;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\tweepy\\api.py:577\u001b[0m, in \u001b[0;36mAPI.user_timeline\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[39m@pagination\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    537\u001b[0m \u001b[39m@payload\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    538\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muser_timeline\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    539\u001b[0m     \u001b[39m\"\"\"user_timeline(*, user_id, screen_name, since_id, count, max_id, \\\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39m                     trim_user, exclude_replies, include_rts)\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[39m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-user_timeline\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    578\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstatuses/user_timeline\u001b[39m\u001b[39m'\u001b[39m, endpoint_parameters\u001b[39m=\u001b[39m(\n\u001b[0;32m    579\u001b[0m             \u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscreen_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msince_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_id\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    580\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mtrim_user\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexclude_replies\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minclude_rts\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    581\u001b[0m         ), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    582\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\tweepy\\api.py:222\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Execute request\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    223\u001b[0m         method, url, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    224\u001b[0m         data\u001b[39m=\u001b[39;49mpost_data, files\u001b[39m=\u001b[39;49mfiles, json\u001b[39m=\u001b[39;49mjson_payload,\n\u001b[0;32m    225\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, auth\u001b[39m=\u001b[39;49mauth, proxies\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m TweepyException(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to send request: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mwith_traceback(sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Keaton\\anaconda3\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    print(f\"\\n{group}:\\n\")\n",
    "    users = list(user_df[group][user_df[group]!= ''])\n",
    "    user_download(api, users, group)\n",
    "    print(f\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of merged data sets of short_term: (45975, 7)\n",
      "size of merged data sets of long_term: (22559, 7)\n",
      "size of merged data sets of controversial: (3387, 7)\n",
      "size of merged data sets of merged_twitter_users: (71921, 7)\n"
     ]
    }
   ],
   "source": [
    "merge = []\n",
    "for group in groups:\n",
    "    merge.append(merge_files(group, display = 0))\n",
    "df_short_term,df_long_term  = merge[0],merge[1]  \n",
    "df_all = merge_all('merge/merged_twitter_users', display = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1620628855005511680</td>\n",
       "      <td>2023-01-31 22:43:23-05:00</td>\n",
       "      <td>WatcherGuru_twitter</td>\n",
       "      <td>190</td>\n",
       "      <td>33</td>\n",
       "      <td>https://twitter.com/i/web/status/1620628855005...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620579693983600640</td>\n",
       "      <td>2023-01-31 19:28:02-05:00</td>\n",
       "      <td>WatcherGuru_twitter</td>\n",
       "      <td>6617</td>\n",
       "      <td>861</td>\n",
       "      <td>https://twitter.com/i/web/status/1620579693983...</td>\n",
       "      <td>JUST IN Jim Cramer says were in a bull market ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 created_at                 user  \\\n",
       "0  1620628855005511680  2023-01-31 22:43:23-05:00  WatcherGuru_twitter   \n",
       "1  1620579693983600640  2023-01-31 19:28:02-05:00  WatcherGuru_twitter   \n",
       "\n",
       "   favorite_count  retweet_count  \\\n",
       "0             190             33   \n",
       "1            6617            861   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://twitter.com/i/web/status/1620628855005...   \n",
       "1  https://twitter.com/i/web/status/1620579693983...   \n",
       "\n",
       "                                                text  \n",
       "0                                                NaN  \n",
       "1  JUST IN Jim Cramer says were in a bull market ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 71921 entries, 0 to 3386\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              71921 non-null  int64 \n",
      " 1   created_at      71921 non-null  object\n",
      " 2   user            71921 non-null  object\n",
      " 3   favorite_count  71921 non-null  int64 \n",
      " 4   retweet_count   71921 non-null  int64 \n",
      " 5   url             71921 non-null  object\n",
      " 6   text            70049 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_all.info(verbose = True, null_counts = None, show_counts=None))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some Analysts have infrequent tweets and have 2k limit of tweets going farther back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "BillGates_twitter          2013-07-03 13:04:11-04:00\n",
       "JeffBezos_twitter          2015-11-24 06:14:26-05:00\n",
       "DanZanger_twitter          2017-04-26 11:09:50-04:00\n",
       "techbudsolution_twitter    2017-04-30 12:25:18-04:00\n",
       "HindenburgRes_twitter      2017-07-31 13:54:11-04:00\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby('user')['created_at'].min().sort_values(ascending= True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding nonessential twitter words to remove\n",
    "stop = nltk.corpus.stopwords.words(\"english\") \n",
    "twitter_nonessential_words = ['twitter', 'birds','lists','list', 'source','just','am','pm'\\\n",
    "                              'a','b','c','d','e','f','g','h','i','j','k','l','m','n',\\\n",
    "                              'n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "stop.extend(twitter_nonessential_words) # merge two lists together\n",
    "stop = sorted(list( dict.fromkeys(stop) )) # remove duplicates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionarys of words \n",
    "* Remove unnecessary words\n",
    "* Generate frequency of words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_words = strip_all_words(df_all, stop)\n",
    "df_all_words_count = df_all_words.explode().replace(\"\", np.nan, regex=True).dropna() # drop NAN's and empty words\n",
    "all_count = df_all_words_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets of Dictionaries: 71921\n",
      "all words: 1017652\n",
      "Dictionary of all words: 45033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tweets of Dictionaries: {len(df_all_words)}\")\n",
    "print(f\"all words: {len(df_all_words_count)}\")\n",
    "print(f\"Dictionary of all words: {len(all_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 words from dictionary of all words:\n",
      "stocks    8762\n",
      "stock     8673\n",
      "today     6048\n",
      "score     5825\n",
      "top       5630\n",
      "Name: text, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"5 words from dictionary of all words:\\n{all_count[0:5]}\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the words in each individual Sentence:\n",
      "0                                                  NaN\n",
      "1        [, jim, cramer, says, bull, market, buy, dip]\n",
      "2                                                  NaN\n",
      "3    [, chatgpt, creator, openai, releases, tool, d...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"All the words in each individual Sentence:\\n{df_all_words[0:4]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note the [','] and 'NaN' variables\n",
    "* Nan is a placeholder for tweets w/ images\n",
    "* [','] are words removed with special cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability small example\n",
    "\n",
    "p = count(particular word in sentence) / (total particular word in all sentences) * 100 / (total of all unique words)\n",
    "\n",
    "d{  hat:1, sandwich:2, lemon:1, orange:1, snorkle:1 }\n",
    "\n",
    "n = LEN(d.KEYS())  -> n = 5\n",
    "\n",
    "Tweet1: hat sandwich lemon \n",
    "\n",
    "Tweet2: snorkle sandwich orange \n",
    "\n",
    "Tweet1:\n",
    "\n",
    "-> 1/1 * 100 + 1/2 * 100 + 1/1 * 100   \n",
    "-> 100 + 50 + 100 = 250\n",
    "-> 250/5 = 50%\n",
    "\n",
    "Tweet2:\n",
    "\n",
    "-> 1/1 * 100 + 1/2 * 100 + 1/1 * 100 \n",
    "-> 100 + 50 + 100 \n",
    "-> 250/5 = 50%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of individual tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of probability column = 99.99999999999832\n"
     ]
    }
   ],
   "source": [
    "# Probabilities\n",
    "sentence_list, total_probability, individual_probability = sentence_word_probability(all_count, df_all_words)\n",
    "print(f'sum of probability column = {sum(total_probability)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_prob = df_all.reset_index()\n",
    "df_all_prob['frequency'] = sentence_list\n",
    "df_all_prob['probability'] = total_probability\n",
    "df_all_prob = df_all_prob.dropna()\n",
    "df_all_prob.insert(loc = 0, column = 'date', value = pd.to_datetime(df_all_prob['created_at']).apply(lambda x: x.strftime('%Y-%m-%d')))\n",
    "df_all_prob.date = pd.to_datetime(df_all_prob['date'], format='%Y-%m-%d')\n",
    "df_all_prob = df_all_prob.sort_values(by=['date'], ascending=False).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>frequency</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>1620579693983600640</td>\n",
       "      <td>2023-01-31 19:28:02-05:00</td>\n",
       "      <td>WatcherGuru_twitter</td>\n",
       "      <td>6617</td>\n",
       "      <td>861</td>\n",
       "      <td>https://twitter.com/i/web/status/1620579693983...</td>\n",
       "      <td>JUST IN Jim Cramer says were in a bull market ...</td>\n",
       "      <td>[{'jim': 1.282051282051282, 'cramer': 1.587301...</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>1620600720813862912</td>\n",
       "      <td>2023-01-31 20:51:35-05:00</td>\n",
       "      <td>TwentyonTwenty__twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/i/web/status/1620600720813...</td>\n",
       "      <td>HILS has trended 96 times in the past 24 hours...</td>\n",
       "      <td>[{'hils': 2.4390243902439024, 'trended': 0.041...</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                   id                 created_at  \\\n",
       "1    2023-01-31  1620579693983600640  2023-01-31 19:28:02-05:00   \n",
       "3228 2023-01-31  1620600720813862912  2023-01-31 20:51:35-05:00   \n",
       "\n",
       "                         user  favorite_count  retweet_count  \\\n",
       "1         WatcherGuru_twitter            6617            861   \n",
       "3228  TwentyonTwenty__twitter               0              0   \n",
       "\n",
       "                                                    url  \\\n",
       "1     https://twitter.com/i/web/status/1620579693983...   \n",
       "3228  https://twitter.com/i/web/status/1620600720813...   \n",
       "\n",
       "                                                   text  \\\n",
       "1     JUST IN Jim Cramer says were in a bull market ...   \n",
       "3228  HILS has trended 96 times in the past 24 hours...   \n",
       "\n",
       "                                              frequency  probability  \n",
       "1     [{'jim': 1.282051282051282, 'cramer': 1.587301...     0.000079  \n",
       "3228  [{'hils': 2.4390243902439024, 'trended': 0.041...     0.000673  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_prob.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide1 = df_all_prob.pivot_table(index='date', values=['favorite_count','retweet_count'], aggfunc='sum',fill_value=0 ).sort_values(by='date',ascending=False)\n",
    "df_wide2 = df_all_prob.pivot_table(index='date', columns=['user'], values=['probability'], aggfunc='sum',fill_value=0 ).sort_values(by='date',ascending=False).droplevel(0, axis=1) \n",
    "df_wide_merge = pd.merge(df_wide1, df_wide2, how='inner', on='date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging Sat/Sun Tweets to Monday and re-merging to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>BillGates_twitter</th>\n",
       "      <th>DanZanger_twitter</th>\n",
       "      <th>DipFinding_twitter</th>\n",
       "      <th>EconguyRosie_twitter</th>\n",
       "      <th>GRDecter_twitter</th>\n",
       "      <th>HindenburgRes_twitter</th>\n",
       "      <th>JeffBezos_twitter</th>\n",
       "      <th>JehoshaphatRsch_twitter</th>\n",
       "      <th>KennethLFisher_twitter</th>\n",
       "      <th>MITickWatcher_twitter</th>\n",
       "      <th>MacroCharts_twitter</th>\n",
       "      <th>MarketMagnifier_twitter</th>\n",
       "      <th>OptionsProVol_twitter</th>\n",
       "      <th>RayDalio_twitter</th>\n",
       "      <th>ResearchGrizzly_twitter</th>\n",
       "      <th>TwentyonTwenty__twitter</th>\n",
       "      <th>WatcherGuru_twitter</th>\n",
       "      <th>andrewrsorkin_twitter</th>\n",
       "      <th>biancoresearch_twitter</th>\n",
       "      <th>bsc_daily_twitter</th>\n",
       "      <th>eWhispers_twitter</th>\n",
       "      <th>jimcramer_twitter</th>\n",
       "      <th>lei_zhang_lz_twitter</th>\n",
       "      <th>markminervini_twitter</th>\n",
       "      <th>muddywatersre_twitter</th>\n",
       "      <th>prrobbins_twitter</th>\n",
       "      <th>realwillmeade_twitter</th>\n",
       "      <th>script_crypto_twitter</th>\n",
       "      <th>techbudsolution_twitter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>88960</td>\n",
       "      <td>11544</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.250276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27</th>\n",
       "      <td>104909</td>\n",
       "      <td>18089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036550</td>\n",
       "      <td>0.177148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26</th>\n",
       "      <td>150375</td>\n",
       "      <td>26356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200485</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.305759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-25</th>\n",
       "      <td>85699</td>\n",
       "      <td>13236</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.273836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046427</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-24</th>\n",
       "      <td>285079</td>\n",
       "      <td>69954</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.118665</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.232013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.005032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            favorite_count  retweet_count  BillGates_twitter  \\\n",
       "date                                                           \n",
       "2023-01-31           88960          11544           0.001227   \n",
       "2023-01-27          104909          18089           0.000050   \n",
       "2023-01-26          150375          26356           0.000000   \n",
       "2023-01-25           85699          13236           0.001683   \n",
       "2023-01-24          285079          69954           0.008739   \n",
       "\n",
       "            DanZanger_twitter  DipFinding_twitter  EconguyRosie_twitter  \\\n",
       "date                                                                      \n",
       "2023-01-31           0.000000            0.098042              0.000000   \n",
       "2023-01-27           0.000000            0.100147              0.000000   \n",
       "2023-01-26           0.000000            0.200485              0.005575   \n",
       "2023-01-25           0.000000            0.159028              0.000000   \n",
       "2023-01-24           0.000975            0.118665              0.004660   \n",
       "\n",
       "            GRDecter_twitter  HindenburgRes_twitter  JeffBezos_twitter  \\\n",
       "date                                                                     \n",
       "2023-01-31          0.047432               0.000000           0.004775   \n",
       "2023-01-27          0.036253               0.000000           0.000000   \n",
       "2023-01-26          0.028691               0.000042           0.000000   \n",
       "2023-01-25          0.014698               0.000000           0.000000   \n",
       "2023-01-24          0.021256               0.215444           0.000000   \n",
       "\n",
       "            JehoshaphatRsch_twitter  KennethLFisher_twitter  \\\n",
       "date                                                          \n",
       "2023-01-31                      0.0                0.016196   \n",
       "2023-01-27                      0.0                0.036550   \n",
       "2023-01-26                      0.0                0.011991   \n",
       "2023-01-25                      0.0                0.002979   \n",
       "2023-01-24                      0.0                0.007183   \n",
       "\n",
       "            MITickWatcher_twitter  MacroCharts_twitter  \\\n",
       "date                                                     \n",
       "2023-01-31               0.250276                  0.0   \n",
       "2023-01-27               0.177148                  0.0   \n",
       "2023-01-26               0.305759                  0.0   \n",
       "2023-01-25               0.273836                  0.0   \n",
       "2023-01-24               0.232013                  0.0   \n",
       "\n",
       "            MarketMagnifier_twitter  OptionsProVol_twitter  RayDalio_twitter  \\\n",
       "date                                                                           \n",
       "2023-01-31                      0.0               0.015573          0.000310   \n",
       "2023-01-27                      0.0               0.016302          0.001641   \n",
       "2023-01-26                      0.0               0.019718          0.009066   \n",
       "2023-01-25                      0.0               0.018296          0.003700   \n",
       "2023-01-24                      0.0               0.018679          0.002453   \n",
       "\n",
       "            ResearchGrizzly_twitter  TwentyonTwenty__twitter  \\\n",
       "date                                                           \n",
       "2023-01-31                      0.0                 0.033493   \n",
       "2023-01-27                      0.0                 0.033853   \n",
       "2023-01-26                      0.0                 0.020702   \n",
       "2023-01-25                      0.0                 0.046427   \n",
       "2023-01-24                      0.0                 0.028910   \n",
       "\n",
       "            WatcherGuru_twitter  andrewrsorkin_twitter  \\\n",
       "date                                                     \n",
       "2023-01-31             0.005971                    0.0   \n",
       "2023-01-27             0.007488                    0.0   \n",
       "2023-01-26             0.005153                    0.0   \n",
       "2023-01-25             0.002730                    0.0   \n",
       "2023-01-24             0.007292                    0.0   \n",
       "\n",
       "            biancoresearch_twitter  bsc_daily_twitter  eWhispers_twitter  \\\n",
       "date                                                                       \n",
       "2023-01-31                0.003709           0.035104           0.013689   \n",
       "2023-01-27                0.007170           0.024795           0.012019   \n",
       "2023-01-26                0.004399           0.012587           0.012938   \n",
       "2023-01-25                0.028858           0.008757           0.015866   \n",
       "2023-01-24                0.005548           0.014595           0.018616   \n",
       "\n",
       "            jimcramer_twitter  lei_zhang_lz_twitter  markminervini_twitter  \\\n",
       "date                                                                         \n",
       "2023-01-31           0.005601              0.000203               0.001552   \n",
       "2023-01-27           0.007180              0.008023               0.000000   \n",
       "2023-01-26           0.008882              0.000000               0.005972   \n",
       "2023-01-25           0.028819              0.000000               0.003097   \n",
       "2023-01-24           0.009024              0.002274               0.000000   \n",
       "\n",
       "            muddywatersre_twitter  prrobbins_twitter  realwillmeade_twitter  \\\n",
       "date                                                                          \n",
       "2023-01-31               0.000000           0.000162               0.044295   \n",
       "2023-01-27               0.002252           0.002466               0.000000   \n",
       "2023-01-26               0.000000           0.003479               0.000000   \n",
       "2023-01-25               0.000000           0.001806               0.009745   \n",
       "2023-01-24               0.000378           0.002954               0.001078   \n",
       "\n",
       "            script_crypto_twitter  techbudsolution_twitter  \n",
       "date                                                        \n",
       "2023-01-31               0.004937                 0.005519  \n",
       "2023-01-27               0.001980                 0.006539  \n",
       "2023-01-26               0.004369                 0.000000  \n",
       "2023-01-25               0.006050                 0.000928  \n",
       "2023-01-24               0.003176                 0.005032  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Saturday-Monday And replace with Monday\n",
    "week_end_mask = df_wide_merge.reset_index().date.dt.day_name().isin(['Saturday', 'Sunday', 'Monday'])\n",
    "week_end = df_wide_merge.reset_index().loc[week_end_mask, :]\n",
    "monday_group = week_end.groupby([pd.Grouper(key='date', freq='W-MON')])[df_wide_merge.columns].sum().reset_index('date')\n",
    "\n",
    "df_wide_stripped = df_wide_merge.reset_index().loc[~ week_end_mask, :]\n",
    "df_wide = pd.merge(df_wide_stripped, monday_group, how='outer').set_index('date')\n",
    "df_wide.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>BillGates_twitter</th>\n",
       "      <th>DanZanger_twitter</th>\n",
       "      <th>DipFinding_twitter</th>\n",
       "      <th>EconguyRosie_twitter</th>\n",
       "      <th>GRDecter_twitter</th>\n",
       "      <th>HindenburgRes_twitter</th>\n",
       "      <th>JeffBezos_twitter</th>\n",
       "      <th>JehoshaphatRsch_twitter</th>\n",
       "      <th>KennethLFisher_twitter</th>\n",
       "      <th>MITickWatcher_twitter</th>\n",
       "      <th>MacroCharts_twitter</th>\n",
       "      <th>MarketMagnifier_twitter</th>\n",
       "      <th>OptionsProVol_twitter</th>\n",
       "      <th>RayDalio_twitter</th>\n",
       "      <th>ResearchGrizzly_twitter</th>\n",
       "      <th>TwentyonTwenty__twitter</th>\n",
       "      <th>WatcherGuru_twitter</th>\n",
       "      <th>andrewrsorkin_twitter</th>\n",
       "      <th>biancoresearch_twitter</th>\n",
       "      <th>bsc_daily_twitter</th>\n",
       "      <th>eWhispers_twitter</th>\n",
       "      <th>jimcramer_twitter</th>\n",
       "      <th>lei_zhang_lz_twitter</th>\n",
       "      <th>markminervini_twitter</th>\n",
       "      <th>muddywatersre_twitter</th>\n",
       "      <th>prrobbins_twitter</th>\n",
       "      <th>realwillmeade_twitter</th>\n",
       "      <th>script_crypto_twitter</th>\n",
       "      <th>techbudsolution_twitter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>88960</td>\n",
       "      <td>11544</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.250276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27</th>\n",
       "      <td>104909</td>\n",
       "      <td>18089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036550</td>\n",
       "      <td>0.177148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26</th>\n",
       "      <td>150375</td>\n",
       "      <td>26356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200485</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.305759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-25</th>\n",
       "      <td>85699</td>\n",
       "      <td>13236</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.273836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046427</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-24</th>\n",
       "      <td>285079</td>\n",
       "      <td>69954</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.118665</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.232013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.005032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            favorite_count  retweet_count  BillGates_twitter  \\\n",
       "date                                                           \n",
       "2023-01-31           88960          11544           0.001227   \n",
       "2023-01-27          104909          18089           0.000050   \n",
       "2023-01-26          150375          26356           0.000000   \n",
       "2023-01-25           85699          13236           0.001683   \n",
       "2023-01-24          285079          69954           0.008739   \n",
       "\n",
       "            DanZanger_twitter  DipFinding_twitter  EconguyRosie_twitter  \\\n",
       "date                                                                      \n",
       "2023-01-31           0.000000            0.098042              0.000000   \n",
       "2023-01-27           0.000000            0.100147              0.000000   \n",
       "2023-01-26           0.000000            0.200485              0.005575   \n",
       "2023-01-25           0.000000            0.159028              0.000000   \n",
       "2023-01-24           0.000975            0.118665              0.004660   \n",
       "\n",
       "            GRDecter_twitter  HindenburgRes_twitter  JeffBezos_twitter  \\\n",
       "date                                                                     \n",
       "2023-01-31          0.047432               0.000000           0.004775   \n",
       "2023-01-27          0.036253               0.000000           0.000000   \n",
       "2023-01-26          0.028691               0.000042           0.000000   \n",
       "2023-01-25          0.014698               0.000000           0.000000   \n",
       "2023-01-24          0.021256               0.215444           0.000000   \n",
       "\n",
       "            JehoshaphatRsch_twitter  KennethLFisher_twitter  \\\n",
       "date                                                          \n",
       "2023-01-31                      0.0                0.016196   \n",
       "2023-01-27                      0.0                0.036550   \n",
       "2023-01-26                      0.0                0.011991   \n",
       "2023-01-25                      0.0                0.002979   \n",
       "2023-01-24                      0.0                0.007183   \n",
       "\n",
       "            MITickWatcher_twitter  MacroCharts_twitter  \\\n",
       "date                                                     \n",
       "2023-01-31               0.250276                  0.0   \n",
       "2023-01-27               0.177148                  0.0   \n",
       "2023-01-26               0.305759                  0.0   \n",
       "2023-01-25               0.273836                  0.0   \n",
       "2023-01-24               0.232013                  0.0   \n",
       "\n",
       "            MarketMagnifier_twitter  OptionsProVol_twitter  RayDalio_twitter  \\\n",
       "date                                                                           \n",
       "2023-01-31                      0.0               0.015573          0.000310   \n",
       "2023-01-27                      0.0               0.016302          0.001641   \n",
       "2023-01-26                      0.0               0.019718          0.009066   \n",
       "2023-01-25                      0.0               0.018296          0.003700   \n",
       "2023-01-24                      0.0               0.018679          0.002453   \n",
       "\n",
       "            ResearchGrizzly_twitter  TwentyonTwenty__twitter  \\\n",
       "date                                                           \n",
       "2023-01-31                      0.0                 0.033493   \n",
       "2023-01-27                      0.0                 0.033853   \n",
       "2023-01-26                      0.0                 0.020702   \n",
       "2023-01-25                      0.0                 0.046427   \n",
       "2023-01-24                      0.0                 0.028910   \n",
       "\n",
       "            WatcherGuru_twitter  andrewrsorkin_twitter  \\\n",
       "date                                                     \n",
       "2023-01-31             0.005971                    0.0   \n",
       "2023-01-27             0.007488                    0.0   \n",
       "2023-01-26             0.005153                    0.0   \n",
       "2023-01-25             0.002730                    0.0   \n",
       "2023-01-24             0.007292                    0.0   \n",
       "\n",
       "            biancoresearch_twitter  bsc_daily_twitter  eWhispers_twitter  \\\n",
       "date                                                                       \n",
       "2023-01-31                0.003709           0.035104           0.013689   \n",
       "2023-01-27                0.007170           0.024795           0.012019   \n",
       "2023-01-26                0.004399           0.012587           0.012938   \n",
       "2023-01-25                0.028858           0.008757           0.015866   \n",
       "2023-01-24                0.005548           0.014595           0.018616   \n",
       "\n",
       "            jimcramer_twitter  lei_zhang_lz_twitter  markminervini_twitter  \\\n",
       "date                                                                         \n",
       "2023-01-31           0.005601              0.000203               0.001552   \n",
       "2023-01-27           0.007180              0.008023               0.000000   \n",
       "2023-01-26           0.008882              0.000000               0.005972   \n",
       "2023-01-25           0.028819              0.000000               0.003097   \n",
       "2023-01-24           0.009024              0.002274               0.000000   \n",
       "\n",
       "            muddywatersre_twitter  prrobbins_twitter  realwillmeade_twitter  \\\n",
       "date                                                                          \n",
       "2023-01-31               0.000000           0.000162               0.044295   \n",
       "2023-01-27               0.002252           0.002466               0.000000   \n",
       "2023-01-26               0.000000           0.003479               0.000000   \n",
       "2023-01-25               0.000000           0.001806               0.009745   \n",
       "2023-01-24               0.000378           0.002954               0.001078   \n",
       "\n",
       "            script_crypto_twitter  techbudsolution_twitter  \n",
       "date                                                        \n",
       "2023-01-31               0.004937                 0.005519  \n",
       "2023-01-27               0.001980                 0.006539  \n",
       "2023-01-26               0.004369                 0.000000  \n",
       "2023-01-25               0.006050                 0.000928  \n",
       "2023-01-24               0.003176                 0.005032  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_all_merged_twitter_analysts_pivot = f'../Sentiment_Analysis/Stock_Market/data/merge/all_merged_twitter_users' # Create Folders\n",
    "if not os.path.exists(path_all_merged_twitter_analysts_pivot):\n",
    "    os.makedirs(path_all_merged_twitter_analysts_pivot)\n",
    "df_wide.to_csv(path_all_merged_twitter_analysts_pivot +'/all_merged_twitter_users_pivot.csv', index=True) # Export to csv\n",
    "\n",
    "df_wide.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINT    \n",
    "    Load pivot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all_merged_twitter_analysts_pivot = f'../Sentiment_Analysis/Stock_Market/data/merge/all_merged_twitter_users'\n",
    "df_wide = pd.read_csv(path_all_merged_twitter_analysts_pivot +'/all_merged_twitter_users_pivot.csv').astype({'date':'datetime64[ns]'}).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_name</th>\n",
       "      <th>ticker_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>SandP_500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^IXIC</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^RUT</td>\n",
       "      <td>RUSSEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>^DJI</td>\n",
       "      <td>DOW_JONES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker_name ticker_label\n",
       "0       ^GSPC    SandP_500\n",
       "1       ^IXIC       NASDAQ\n",
       "2        ^RUT       RUSSEL\n",
       "3        ^DJI    DOW_JONES"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.normpath(os.getcwd() + '/Stock_Market/ticker_list/ticker_list.xlsx'), 'rb') as f:\n",
    "    ticker_df = pd.read_excel(f, sheet_name='ticker_sheet')\n",
    "    ticker_df = ticker_df.where(pd.notnull(ticker_df), '')\n",
    "    f.close()\n",
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-07-03 -> 2023-02-01\n"
     ]
    }
   ],
   "source": [
    "# downloding index fund's or stock tickers  #.resample('D').ffill()\n",
    "how_far_back = df_wide.index.min().date()\n",
    "today = date.today()\n",
    "column_names = dict(zip(ticker_df.ticker_name, ticker_df.ticker_label))\n",
    "column_names['Date']='date'\n",
    "stock_list = list(ticker_df.ticker_name)\n",
    "stock_str = ' '.join( stock_list )\n",
    "\n",
    "index_funds_df = yf.download(stock_str, how_far_back, today, interval = '1d', progress=False)['Close'].reset_index('Date').rename(columns=column_names)\n",
    "\n",
    "convert_dict = dict(zip(ticker_df.ticker_label, ['float64']*len(ticker_df.ticker_label)))\n",
    "convert_dict['date'] = 'datetime64[ns]'\n",
    "index_funds_df = index_funds_df.astype(convert_dict)\n",
    "\n",
    "print(f'{how_far_back} -> {today}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>DOW_JONES</th>\n",
       "      <th>SandP_500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>RUSSEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>14988.370117</td>\n",
       "      <td>1615.410034</td>\n",
       "      <td>3443.669922</td>\n",
       "      <td>991.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>15135.839844</td>\n",
       "      <td>1631.890015</td>\n",
       "      <td>3479.379883</td>\n",
       "      <td>1005.390015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-08</td>\n",
       "      <td>15224.690430</td>\n",
       "      <td>1640.459961</td>\n",
       "      <td>3484.830078</td>\n",
       "      <td>1009.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-09</td>\n",
       "      <td>15300.339844</td>\n",
       "      <td>1652.319946</td>\n",
       "      <td>3504.260010</td>\n",
       "      <td>1018.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>15291.660156</td>\n",
       "      <td>1652.619995</td>\n",
       "      <td>3520.760010</td>\n",
       "      <td>1020.419983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     DOW_JONES    SandP_500       NASDAQ       RUSSEL\n",
       "0 2013-07-03  14988.370117  1615.410034  3443.669922   991.130005\n",
       "1 2013-07-05  15135.839844  1631.890015  3479.379883  1005.390015\n",
       "2 2013-07-08  15224.690430  1640.459961  3484.830078  1009.250000\n",
       "3 2013-07-09  15300.339844  1652.319946  3504.260010  1018.049988\n",
       "4 2013-07-10  15291.660156  1652.619995  3520.760010  1020.419983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_index_funds_merge = f'../Sentiment_Analysis/Stock_Market/data/merge/all_merged_index_funds' # Create Folders\n",
    "if not os.path.exists(path_index_funds_merge):\n",
    "    os.makedirs(path_index_funds_merge)\n",
    "index_funds_df.to_csv(path_index_funds_merge +'/all_merged_index_funds.csv', index=False) # Export to csv\n",
    "index_funds_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOW_JONES</th>\n",
       "      <th>SandP_500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>RUSSEL</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>BillGates_twitter</th>\n",
       "      <th>DanZanger_twitter</th>\n",
       "      <th>DipFinding_twitter</th>\n",
       "      <th>EconguyRosie_twitter</th>\n",
       "      <th>GRDecter_twitter</th>\n",
       "      <th>HindenburgRes_twitter</th>\n",
       "      <th>JeffBezos_twitter</th>\n",
       "      <th>JehoshaphatRsch_twitter</th>\n",
       "      <th>KennethLFisher_twitter</th>\n",
       "      <th>MITickWatcher_twitter</th>\n",
       "      <th>MacroCharts_twitter</th>\n",
       "      <th>MarketMagnifier_twitter</th>\n",
       "      <th>OptionsProVol_twitter</th>\n",
       "      <th>RayDalio_twitter</th>\n",
       "      <th>ResearchGrizzly_twitter</th>\n",
       "      <th>TwentyonTwenty__twitter</th>\n",
       "      <th>WatcherGuru_twitter</th>\n",
       "      <th>andrewrsorkin_twitter</th>\n",
       "      <th>biancoresearch_twitter</th>\n",
       "      <th>bsc_daily_twitter</th>\n",
       "      <th>eWhispers_twitter</th>\n",
       "      <th>jimcramer_twitter</th>\n",
       "      <th>lei_zhang_lz_twitter</th>\n",
       "      <th>markminervini_twitter</th>\n",
       "      <th>muddywatersre_twitter</th>\n",
       "      <th>prrobbins_twitter</th>\n",
       "      <th>realwillmeade_twitter</th>\n",
       "      <th>script_crypto_twitter</th>\n",
       "      <th>techbudsolution_twitter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-25</th>\n",
       "      <td>0.861245</td>\n",
       "      <td>0.754699</td>\n",
       "      <td>0.623897</td>\n",
       "      <td>0.629004</td>\n",
       "      <td>0.171341</td>\n",
       "      <td>0.153948</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.273836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046427</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26</th>\n",
       "      <td>0.870580</td>\n",
       "      <td>0.768596</td>\n",
       "      <td>0.639677</td>\n",
       "      <td>0.637560</td>\n",
       "      <td>0.300651</td>\n",
       "      <td>0.306547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200485</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.305759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27</th>\n",
       "      <td>0.871881</td>\n",
       "      <td>0.771781</td>\n",
       "      <td>0.648342</td>\n",
       "      <td>0.643202</td>\n",
       "      <td>0.209749</td>\n",
       "      <td>0.210393</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036550</td>\n",
       "      <td>0.177148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-30</th>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.755186</td>\n",
       "      <td>0.630275</td>\n",
       "      <td>0.625915</td>\n",
       "      <td>0.448162</td>\n",
       "      <td>0.575840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.063835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033161</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.103975</td>\n",
       "      <td>0.016783</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.020830</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.069552</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>0.876784</td>\n",
       "      <td>0.773679</td>\n",
       "      <td>0.645396</td>\n",
       "      <td>0.656959</td>\n",
       "      <td>0.177861</td>\n",
       "      <td>0.134268</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.250276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.005519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DOW_JONES  SandP_500    NASDAQ    RUSSEL  favorite_count  \\\n",
       "date                                                                   \n",
       "2023-01-25   0.861245   0.754699  0.623897  0.629004        0.171341   \n",
       "2023-01-26   0.870580   0.768596  0.639677  0.637560        0.300651   \n",
       "2023-01-27   0.871881   0.771781  0.648342  0.643202        0.209749   \n",
       "2023-01-30   0.860031   0.755186  0.630275  0.625915        0.448162   \n",
       "2023-01-31   0.876784   0.773679  0.645396  0.656959        0.177861   \n",
       "\n",
       "            retweet_count  BillGates_twitter  DanZanger_twitter  \\\n",
       "date                                                              \n",
       "2023-01-25       0.153948           0.001683           0.000000   \n",
       "2023-01-26       0.306547           0.000000           0.000000   \n",
       "2023-01-27       0.210393           0.000050           0.000000   \n",
       "2023-01-30       0.575840           0.000000           0.000038   \n",
       "2023-01-31       0.134268           0.001227           0.000000   \n",
       "\n",
       "            DipFinding_twitter  EconguyRosie_twitter  GRDecter_twitter  \\\n",
       "date                                                                     \n",
       "2023-01-25            0.159028              0.000000          0.014698   \n",
       "2023-01-26            0.200485              0.005575          0.028691   \n",
       "2023-01-27            0.100147              0.000000          0.036253   \n",
       "2023-01-30            0.063835              0.000000          0.033161   \n",
       "2023-01-31            0.098042              0.000000          0.047432   \n",
       "\n",
       "            HindenburgRes_twitter  JeffBezos_twitter  JehoshaphatRsch_twitter  \\\n",
       "date                                                                            \n",
       "2023-01-25               0.000000           0.000000                      0.0   \n",
       "2023-01-26               0.000042           0.000000                      0.0   \n",
       "2023-01-27               0.000000           0.000000                      0.0   \n",
       "2023-01-30               0.004541           0.000379                      0.0   \n",
       "2023-01-31               0.000000           0.004775                      0.0   \n",
       "\n",
       "            KennethLFisher_twitter  MITickWatcher_twitter  \\\n",
       "date                                                        \n",
       "2023-01-25                0.002979               0.273836   \n",
       "2023-01-26                0.011991               0.305759   \n",
       "2023-01-27                0.036550               0.177148   \n",
       "2023-01-30                0.018193               0.258850   \n",
       "2023-01-31                0.016196               0.250276   \n",
       "\n",
       "            MacroCharts_twitter  MarketMagnifier_twitter  \\\n",
       "date                                                       \n",
       "2023-01-25                  0.0                      0.0   \n",
       "2023-01-26                  0.0                      0.0   \n",
       "2023-01-27                  0.0                      0.0   \n",
       "2023-01-30                  0.0                      0.0   \n",
       "2023-01-31                  0.0                      0.0   \n",
       "\n",
       "            OptionsProVol_twitter  RayDalio_twitter  ResearchGrizzly_twitter  \\\n",
       "date                                                                           \n",
       "2023-01-25               0.018296          0.003700                      0.0   \n",
       "2023-01-26               0.019718          0.009066                      0.0   \n",
       "2023-01-27               0.016302          0.001641                      0.0   \n",
       "2023-01-30               0.018314          0.005288                      0.0   \n",
       "2023-01-31               0.015573          0.000310                      0.0   \n",
       "\n",
       "            TwentyonTwenty__twitter  WatcherGuru_twitter  \\\n",
       "date                                                       \n",
       "2023-01-25                 0.046427             0.002730   \n",
       "2023-01-26                 0.020702             0.005153   \n",
       "2023-01-27                 0.033853             0.007488   \n",
       "2023-01-30                 0.094105             0.006956   \n",
       "2023-01-31                 0.033493             0.005971   \n",
       "\n",
       "            andrewrsorkin_twitter  biancoresearch_twitter  bsc_daily_twitter  \\\n",
       "date                                                                           \n",
       "2023-01-25               0.000000                0.028858           0.008757   \n",
       "2023-01-26               0.000000                0.004399           0.012587   \n",
       "2023-01-27               0.000000                0.007170           0.024795   \n",
       "2023-01-30               0.000004                0.007009           0.103975   \n",
       "2023-01-31               0.000000                0.003709           0.035104   \n",
       "\n",
       "            eWhispers_twitter  jimcramer_twitter  lei_zhang_lz_twitter  \\\n",
       "date                                                                     \n",
       "2023-01-25           0.015866           0.028819              0.000000   \n",
       "2023-01-26           0.012938           0.008882              0.000000   \n",
       "2023-01-27           0.012019           0.007180              0.008023   \n",
       "2023-01-30           0.016783           0.018751              0.007512   \n",
       "2023-01-31           0.013689           0.005601              0.000203   \n",
       "\n",
       "            markminervini_twitter  muddywatersre_twitter  prrobbins_twitter  \\\n",
       "date                                                                          \n",
       "2023-01-25               0.003097               0.000000           0.001806   \n",
       "2023-01-26               0.005972               0.000000           0.003479   \n",
       "2023-01-27               0.000000               0.002252           0.002466   \n",
       "2023-01-30               0.002270               0.020830           0.004558   \n",
       "2023-01-31               0.001552               0.000000           0.000162   \n",
       "\n",
       "            realwillmeade_twitter  script_crypto_twitter  \\\n",
       "date                                                       \n",
       "2023-01-25               0.009745               0.006050   \n",
       "2023-01-26               0.000000               0.004369   \n",
       "2023-01-27               0.000000               0.001980   \n",
       "2023-01-30               0.069552               0.004363   \n",
       "2023-01-31               0.044295               0.004937   \n",
       "\n",
       "            techbudsolution_twitter  \n",
       "date                                 \n",
       "2023-01-25                 0.000928  \n",
       "2023-01-26                 0.000000  \n",
       "2023-01-27                 0.006539  \n",
       "2023-01-30                 0.002362  \n",
       "2023-01-31                 0.005519  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the probabilities of words used from twitter and database of index funds\n",
    "df_merge = pd.merge(index_funds_df, df_wide, how='inner', on='date').set_index('date')\n",
    "df_merge_original = df_merge.copy()\n",
    "\n",
    "columns = list(ticker_df.ticker_label) + ['favorite_count', 'retweet_count']\n",
    "df_merge = normalize_columns(df_merge.copy(), columns)\n",
    "df_merge.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_twitter_and_index_fund = f'../Sentiment_Analysis/Stock_Market/data/merge/combined'\n",
    "if not os.path.exists(path_twitter_and_index_fund):\n",
    "    os.makedirs(path_twitter_and_index_fund)\n",
    "df_merge.to_csv(path_twitter_and_index_fund +'/index_funds_and_twitter_analysts.csv') # Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOW_JONES</th>\n",
       "      <th>SandP_500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>RUSSEL</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>BillGates_twitter</th>\n",
       "      <th>DanZanger_twitter</th>\n",
       "      <th>DipFinding_twitter</th>\n",
       "      <th>EconguyRosie_twitter</th>\n",
       "      <th>GRDecter_twitter</th>\n",
       "      <th>HindenburgRes_twitter</th>\n",
       "      <th>JeffBezos_twitter</th>\n",
       "      <th>JehoshaphatRsch_twitter</th>\n",
       "      <th>KennethLFisher_twitter</th>\n",
       "      <th>MITickWatcher_twitter</th>\n",
       "      <th>MacroCharts_twitter</th>\n",
       "      <th>MarketMagnifier_twitter</th>\n",
       "      <th>OptionsProVol_twitter</th>\n",
       "      <th>RayDalio_twitter</th>\n",
       "      <th>ResearchGrizzly_twitter</th>\n",
       "      <th>TwentyonTwenty__twitter</th>\n",
       "      <th>WatcherGuru_twitter</th>\n",
       "      <th>andrewrsorkin_twitter</th>\n",
       "      <th>biancoresearch_twitter</th>\n",
       "      <th>bsc_daily_twitter</th>\n",
       "      <th>eWhispers_twitter</th>\n",
       "      <th>jimcramer_twitter</th>\n",
       "      <th>lei_zhang_lz_twitter</th>\n",
       "      <th>markminervini_twitter</th>\n",
       "      <th>muddywatersre_twitter</th>\n",
       "      <th>prrobbins_twitter</th>\n",
       "      <th>realwillmeade_twitter</th>\n",
       "      <th>script_crypto_twitter</th>\n",
       "      <th>techbudsolution_twitter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-09</th>\n",
       "      <td>0.023785</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10</th>\n",
       "      <td>0.023390</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.044795</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.060160</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.057105</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DOW_JONES  SandP_500    NASDAQ    RUSSEL  favorite_count  \\\n",
       "date                                                                   \n",
       "2013-07-03   0.009619   0.000000  0.000000  0.025124        0.000310   \n",
       "2013-07-09   0.023785   0.011603  0.004803  0.043203        0.000650   \n",
       "2013-07-10   0.023390   0.011697  0.006112  0.044795        0.002203   \n",
       "2013-07-15   0.032136   0.021090  0.012987  0.060160        0.000688   \n",
       "2013-07-16   0.030664   0.019128  0.012275  0.057105        0.000354   \n",
       "\n",
       "            retweet_count  BillGates_twitter  DanZanger_twitter  \\\n",
       "date                                                              \n",
       "2013-07-03       0.006292           0.001897                0.0   \n",
       "2013-07-09       0.004966           0.000507                0.0   \n",
       "2013-07-10       0.017772           0.001679                0.0   \n",
       "2013-07-15       0.009351           0.007076                0.0   \n",
       "2013-07-16       0.004350           0.002902                0.0   \n",
       "\n",
       "            DipFinding_twitter  EconguyRosie_twitter  GRDecter_twitter  \\\n",
       "date                                                                     \n",
       "2013-07-03                 0.0                   0.0               0.0   \n",
       "2013-07-09                 0.0                   0.0               0.0   \n",
       "2013-07-10                 0.0                   0.0               0.0   \n",
       "2013-07-15                 0.0                   0.0               0.0   \n",
       "2013-07-16                 0.0                   0.0               0.0   \n",
       "\n",
       "            HindenburgRes_twitter  JeffBezos_twitter  JehoshaphatRsch_twitter  \\\n",
       "date                                                                            \n",
       "2013-07-03                    0.0                0.0                      0.0   \n",
       "2013-07-09                    0.0                0.0                      0.0   \n",
       "2013-07-10                    0.0                0.0                      0.0   \n",
       "2013-07-15                    0.0                0.0                      0.0   \n",
       "2013-07-16                    0.0                0.0                      0.0   \n",
       "\n",
       "            KennethLFisher_twitter  MITickWatcher_twitter  \\\n",
       "date                                                        \n",
       "2013-07-03                     0.0                    0.0   \n",
       "2013-07-09                     0.0                    0.0   \n",
       "2013-07-10                     0.0                    0.0   \n",
       "2013-07-15                     0.0                    0.0   \n",
       "2013-07-16                     0.0                    0.0   \n",
       "\n",
       "            MacroCharts_twitter  MarketMagnifier_twitter  \\\n",
       "date                                                       \n",
       "2013-07-03                  0.0                      0.0   \n",
       "2013-07-09                  0.0                      0.0   \n",
       "2013-07-10                  0.0                      0.0   \n",
       "2013-07-15                  0.0                      0.0   \n",
       "2013-07-16                  0.0                      0.0   \n",
       "\n",
       "            OptionsProVol_twitter  RayDalio_twitter  ResearchGrizzly_twitter  \\\n",
       "date                                                                           \n",
       "2013-07-03                    0.0               0.0                      0.0   \n",
       "2013-07-09                    0.0               0.0                      0.0   \n",
       "2013-07-10                    0.0               0.0                      0.0   \n",
       "2013-07-15                    0.0               0.0                      0.0   \n",
       "2013-07-16                    0.0               0.0                      0.0   \n",
       "\n",
       "            TwentyonTwenty__twitter  WatcherGuru_twitter  \\\n",
       "date                                                       \n",
       "2013-07-03                      0.0                  0.0   \n",
       "2013-07-09                      0.0                  0.0   \n",
       "2013-07-10                      0.0                  0.0   \n",
       "2013-07-15                      0.0                  0.0   \n",
       "2013-07-16                      0.0                  0.0   \n",
       "\n",
       "            andrewrsorkin_twitter  biancoresearch_twitter  bsc_daily_twitter  \\\n",
       "date                                                                           \n",
       "2013-07-03                    0.0                     0.0                0.0   \n",
       "2013-07-09                    0.0                     0.0                0.0   \n",
       "2013-07-10                    0.0                     0.0                0.0   \n",
       "2013-07-15                    0.0                     0.0                0.0   \n",
       "2013-07-16                    0.0                     0.0                0.0   \n",
       "\n",
       "            eWhispers_twitter  jimcramer_twitter  lei_zhang_lz_twitter  \\\n",
       "date                                                                     \n",
       "2013-07-03                0.0                0.0                   0.0   \n",
       "2013-07-09                0.0                0.0                   0.0   \n",
       "2013-07-10                0.0                0.0                   0.0   \n",
       "2013-07-15                0.0                0.0                   0.0   \n",
       "2013-07-16                0.0                0.0                   0.0   \n",
       "\n",
       "            markminervini_twitter  muddywatersre_twitter  prrobbins_twitter  \\\n",
       "date                                                                          \n",
       "2013-07-03                    0.0                    0.0                0.0   \n",
       "2013-07-09                    0.0                    0.0                0.0   \n",
       "2013-07-10                    0.0                    0.0                0.0   \n",
       "2013-07-15                    0.0                    0.0                0.0   \n",
       "2013-07-16                    0.0                    0.0                0.0   \n",
       "\n",
       "            realwillmeade_twitter  script_crypto_twitter  \\\n",
       "date                                                       \n",
       "2013-07-03                    0.0                    0.0   \n",
       "2013-07-09                    0.0                    0.0   \n",
       "2013-07-10                    0.0                    0.0   \n",
       "2013-07-15                    0.0                    0.0   \n",
       "2013-07-16                    0.0                    0.0   \n",
       "\n",
       "            techbudsolution_twitter  \n",
       "date                                 \n",
       "2013-07-03                      0.0  \n",
       "2013-07-09                      0.0  \n",
       "2013-07-10                      0.0  \n",
       "2013-07-15                      0.0  \n",
       "2013-07-16                      0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_twitter_and_index_fund = f'../Sentiment_Analysis/Stock_Market/data/merge/combined'\n",
    "df_merge = pd.read_csv(path_twitter_and_index_fund +'/index_funds_and_twitter_analysts.csv').set_index('date')\n",
    "df_merge.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Today \n",
    "* ( Between 0 & 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2023-01-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SandP_500</td>\n",
       "      <td>0.666998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>0.518180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSEL</td>\n",
       "      <td>0.706117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOW_JONES</td>\n",
       "      <td>0.650239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  prediction\n",
       "0  SandP_500    0.666998\n",
       "0     NASDAQ    0.518180\n",
       "0     RUSSEL    0.706117\n",
       "0  DOW_JONES    0.650239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Todays Data\n",
    "todays_test = download_todays_test(ticker_df, df_wide, df_merge_original)\n",
    "Xnew = sm.add_constant(todays_test, has_constant='add')\n",
    "\n",
    "model = {} # Model Build For Each index fund\n",
    "print(f\"date: { todays_test.index.date.max() }\")\n",
    "output = pd.DataFrame(columns=['index', 'prediction'])\n",
    "for t in ticker_df.ticker_label:\n",
    "    data_with_target = create_target(df_merge.copy(), day = 5, ticker = t)\n",
    "    m = linear_model(data_with_target,split=0.20,summary = False)\n",
    "    y_pred = m['lm'].predict(Xnew)\n",
    "    model[t] = (y_pred, m)\n",
    "    output = pd.concat([output, pd.DataFrame.from_records([(t, y_pred[0])], columns=['index', 'prediction'])])\n",
    "    \n",
    "display(output)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "829c3b8be07045a118e2051d32961b742b1ec2887b2f995a302577c84815eb30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
